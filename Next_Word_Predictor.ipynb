{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aman78695/LSTM_Next_Word_Prediction/blob/main/Next_Word_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3rq-KmoERcu"
      },
      "outputs": [],
      "source": [
        "data=\"\"\"Q1: What is fine-tuning, and why is it essential for large language models?\n",
        "A1: Fine-tuning is adapting pre-trained language models to specific tasks and domains. It complements pre-training and enables models to excel in particular contexts, making them more powerful and effective for real-world applications.\n",
        "Q2: What are multitask fine-tuning and instruction fine-tuning?\n",
        "A2: Multitask fine-tuning involves training a model on multiple related tasks simultaneously, enhancing its ability to transfer knowledge across tasks. Instruction fine-tuning introduces prompts or instructions during training, allowing fine-grained control over the model's behavior.\n",
        "Q3: How can parameter-efficient fine-tuning benefit NLP tasks?\n",
        "A3: Parameter-efficient fine-tuning reduces the computational resources required, making it more accessible for low-resource environments while maintaining comparable performance to standard fine-tuning.\n",
        "Q4: Will fine-tuning a model cause overfitting to my specific dataset?\n",
        "A4: While fine-tuning can lead to overfitting on small datasets, techniques like early stopping, dropout, and data augmentation can mitigate this risk and promote generalization to new data.\n",
        "Q5: How can I fine-tune a language model for my task if labeled data is limited?\n",
        "A5: In scenarios with limited labeled data, transfer learning from related tasks or leveraging pre-training on similar datasets can help improve the model's performance and adaptability. Also, few-shot learning and data augmentation techniques can be useful for low-resource scenarios.\n",
        "Q6: What is LLama2?\n",
        "A6: LLama2 is large language models by meta that is facebook.\n",
        "Q7: What is Falcon?\n",
        "A7:Falcon is a bus going fro sheohar to muzaffarpur.\n",
        "Q8: What is the difference between pre-training and fine-tuning in the context of language models?\n",
        "A8: Pre-training involves training a language model on a large corpus of text to learn general language patterns and knowledge. Fine-tuning, on the other hand, is the process of taking a pre-trained model and adapting it to a specific task or domain by further training it on task-specific data. Pre-training provides the model with a broad understanding of language, while fine-tuning tailors it to perform well on a particular task.\n",
        "Q9: How does attention mechanism work in language models like GPT-3?\n",
        "A9: Attention mechanisms in models like GPT-3 enable the model to focus on different parts of the input sequence when generating output. It assigns weights to each input token, indicating its importance. The model computes a weighted sum of the token embeddings based on these weights, allowing it to capture dependencies and relationships within the sequence. This mechanism improves the model's ability to handle long-range dependencies and understand context.\n",
        "Q10: What is the role of embeddings in natural language processing?\n",
        "A10: Embeddings are representations of words or tokens in a vector space. In NLP, word embeddings like Word2Vec or GloVe map words to continuous-valued vectors, capturing semantic relationships between words. These embeddings are used to convert discrete words into a format that neural networks can process. They help NLP models understand the meaning and context of words, which is crucial for various NLP tasks.\n",
        "Q11: Can you explain the concept of transfer learning in NLP?\n",
        "A11: Transfer learning in NLP involves using knowledge gained from one task or dataset to improve performance on another related task. Pre-trained language models, like BERT or GPT, are excellent examples of transfer learning in NLP. These models are first trained on a massive amount of text data to learn language patterns, and then their knowledge is transferred to downstream tasks, such as sentiment analysis or named entity recognition, with fine-tuning.\n",
        "Q12: How do language models like BERT handle contextual information in text?\n",
        "A12: Language models like BERT capture contextual information by considering the entire context of a word within a sentence. They use a bidirectional architecture, which means they look at both left and right context words when processing a word. This allows BERT to understand how a word's meaning can change depending on the surrounding words, making it proficient at tasks that require understanding context, like sentence completion or text classification.\n",
        "Q13: What are some common evaluation metrics for NLP tasks like sentiment analysis?\n",
        "A13: Common evaluation metrics for sentiment analysis and other NLP tasks include accuracy, precision, recall, F1 score, and ROC-AUC for binary classification tasks. For multi-class classification, metrics like micro-averaged F1 score, macro-averaged F1 score, and confusion matrices are often used. Additionally, some tasks might use specialized metrics like BLEU or ROUGE for machine translation or text summarization.\n",
        "Q14: What is the significance of the Transformer architecture in modern NLP models?\n",
        "A14: The Transformer architecture, introduced in the \"Attention Is All You Need\" paper, revolutionized NLP by introducing a highly parallelizable architecture that leverages self-attention mechanisms. Transformers have enabled the development of models like BERT, GPT, and many others, which have set new benchmarks in various NLP tasks due to their ability to capture long-range dependencies and context effectively.\n",
        "Q15: How does zero-shot learning differ from few-shot learning in language models?\n",
        "A15: Zero-shot learning involves a model making predictions for classes or tasks it has never seen during training. Few-shot learning, on the other hand, allows the model to learn from a limited number of examples (a few shots) for a new task. Zero-shot learning relies on the model's generalization, while few-shot learning relies on both generalization and adaptation to specific examples.\n",
        "Q16: What is the impact of model size on the performance of language models?\n",
        "A16: Model size has a significant impact on language model performance. Larger models, with more parameters, often have the potential to capture more complex language patterns and perform better on various tasks. However, they also require more computational resources and memory. Model size is a trade-off between performance and resource constraints.\n",
        "Q17: Can you describe the concept of self-attention in Transformer models?\n",
        "A17: Self-attention in Transformer models allows each input token to weigh the importance of other tokens in the sequence when generating output. It computes attention scores for all tokens, and these scores determine how much focus the model should place on each token. Self-attention enables capturing long-range dependencies and contextual information efficiently, making it a crucial component in Transformer-based models.\n",
        "Q18: How do language models handle out-of-vocabulary words in text data?\n",
        "A18: Language models typically handle out-of-vocabulary (OOV) words by breaking down text into subword units or using subword embeddings like Byte-Pair Encoding (BPE) or WordPiece. This allows models to represent previously unseen words as combinations of known subword units. OOV words are less of an issue in models trained with subword tokenization because they can handle a vast vocabulary of subword units.\n",
        "Q19: What is the difference between generative and discriminative models in NLP?\n",
        "A19: Generative models aim to model the entire probability distribution of the data, including the generation of new samples. Examples include sequence-to-sequence models and autoencoders. Discriminative models, on the other hand, focus on learning the boundary between classes or categories in the data and are used for tasks like classification or sentiment analysis. They aim to discriminate between different data categories rather than generating new data.\n",
        "Q20: How can bias in language models be addressed to ensure fairness in AI applications?\n",
        "A20: Addressing bias in language models involves careful data curation, pre-processing, and model design. Techniques such as debiasing training data, re-weighting examples, and auditing model outputs for bias can help mitigate bias. Moreover, involving diverse teams and ethical considerations during model development is essential to promote fairness and reduce bias in AI applications.\n",
        "Q21: What are the key challenges in building multilingual language models?\n",
        "A21: Building multilingual language models poses challenges like handling diverse language structures, resource availability for low-resource languages, and managing the model's size and complexity. Ensuring the model's effectiveness across languages and mitigating potential biases are also important considerations.\n",
        "Q22: How do NLP models like GPT-3 generate coherent and contextually relevant text?\n",
        "A22: NLP models like GPT-3 generate coherent text by using their pre-trained knowledge of language patterns and context. They employ autoregressive decoding, where they generate one token at a time based on the context of previously generated tokens. This process continues until the desired text length is reached, ensuring coherence and relevance to the input or prompt.\n",
        "Q23: What are the potential ethical considerations when deploying large language models?\n",
        "A23: Ethical considerations when deploying large language models include addressing biases in training data, ensuring transparency and interpretability of model outputs, guarding against malicious use, and respecting privacy concerns. Large language models can have unintended consequences, and responsible deployment is essential to mitigate these risks.\n",
        "Q24: How do masked language models like BERT perform word prediction tasks?\n",
        "A24: Masked language models like BERT perform word prediction tasks by randomly masking some words in a sentence and then predicting\n",
        "Q25: What is DragNUWA?\n",
        "A25: DragNUWA is an AI Model That Can Achieve Controllable Video Generation.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "WDFXxtbAF_lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token=Tokenizer()"
      ],
      "metadata": {
        "id": "nus5c2JDGY18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "sbuEZEhVGeKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHIE358EGpUB",
        "outputId": "5daaa21b-41b4-4fb0-c940-00d3a2afde39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'models': 3,\n",
              " 'to': 4,\n",
              " 'language': 5,\n",
              " 'in': 6,\n",
              " 'a': 7,\n",
              " 'of': 8,\n",
              " 'is': 9,\n",
              " 'on': 10,\n",
              " 'model': 11,\n",
              " 'like': 12,\n",
              " 'tasks': 13,\n",
              " 'fine': 14,\n",
              " 'for': 15,\n",
              " 'or': 16,\n",
              " 'tuning': 17,\n",
              " 'can': 18,\n",
              " 'nlp': 19,\n",
              " 'data': 20,\n",
              " 'what': 21,\n",
              " 'it': 22,\n",
              " 'training': 23,\n",
              " 'are': 24,\n",
              " 'learning': 25,\n",
              " 'words': 26,\n",
              " 'how': 27,\n",
              " 'pre': 28,\n",
              " 'text': 29,\n",
              " 'context': 30,\n",
              " 'attention': 31,\n",
              " 'they': 32,\n",
              " 'task': 33,\n",
              " 'shot': 34,\n",
              " 'by': 35,\n",
              " 'bert': 36,\n",
              " 'large': 37,\n",
              " 'trained': 38,\n",
              " \"model's\": 39,\n",
              " 'performance': 40,\n",
              " 'between': 41,\n",
              " 'gpt': 42,\n",
              " 'embeddings': 43,\n",
              " 'specific': 44,\n",
              " 'making': 45,\n",
              " 'more': 46,\n",
              " 'involves': 47,\n",
              " 'transfer': 48,\n",
              " 'knowledge': 49,\n",
              " 'resource': 50,\n",
              " 'this': 51,\n",
              " 'new': 52,\n",
              " 'with': 53,\n",
              " 'few': 54,\n",
              " 'that': 55,\n",
              " 'other': 56,\n",
              " 'sequence': 57,\n",
              " 'when': 58,\n",
              " 'token': 59,\n",
              " 'these': 60,\n",
              " 'handle': 61,\n",
              " 'word': 62,\n",
              " 'examples': 63,\n",
              " 'transformer': 64,\n",
              " 'subword': 65,\n",
              " 'bias': 66,\n",
              " 'while': 67,\n",
              " 'from': 68,\n",
              " 'patterns': 69,\n",
              " 'perform': 70,\n",
              " '3': 71,\n",
              " 'input': 72,\n",
              " 'capture': 73,\n",
              " 'dependencies': 74,\n",
              " 'tokens': 75,\n",
              " 'sentiment': 76,\n",
              " 'analysis': 77,\n",
              " 'do': 78,\n",
              " 'architecture': 79,\n",
              " 'allows': 80,\n",
              " 'classification': 81,\n",
              " 'metrics': 82,\n",
              " 'self': 83,\n",
              " 'have': 84,\n",
              " 'size': 85,\n",
              " 'considerations': 86,\n",
              " 'essential': 87,\n",
              " 'applications': 88,\n",
              " 'related': 89,\n",
              " 'ability': 90,\n",
              " 'during': 91,\n",
              " 'low': 92,\n",
              " 'techniques': 93,\n",
              " 'mitigate': 94,\n",
              " 'generalization': 95,\n",
              " 'limited': 96,\n",
              " 'help': 97,\n",
              " 'also': 98,\n",
              " 'learn': 99,\n",
              " 'hand': 100,\n",
              " 'process': 101,\n",
              " 'focus': 102,\n",
              " 'generating': 103,\n",
              " 'each': 104,\n",
              " 'based': 105,\n",
              " 'long': 106,\n",
              " 'range': 107,\n",
              " 'understand': 108,\n",
              " 'processing': 109,\n",
              " 'used': 110,\n",
              " 'which': 111,\n",
              " 'various': 112,\n",
              " 'you': 113,\n",
              " 'using': 114,\n",
              " 'their': 115,\n",
              " 'as': 116,\n",
              " 'contextual': 117,\n",
              " 'information': 118,\n",
              " 'sentence': 119,\n",
              " 'use': 120,\n",
              " 'at': 121,\n",
              " 'some': 122,\n",
              " 'include': 123,\n",
              " 'f1': 124,\n",
              " 'score': 125,\n",
              " 'zero': 126,\n",
              " 'potential': 127,\n",
              " 'vocabulary': 128,\n",
              " 'units': 129,\n",
              " 'ai': 130,\n",
              " 'ethical': 131,\n",
              " 'ensuring': 132,\n",
              " 'generate': 133,\n",
              " 'adapting': 134,\n",
              " 'enables': 135,\n",
              " 'particular': 136,\n",
              " 'multitask': 137,\n",
              " 'instruction': 138,\n",
              " 'its': 139,\n",
              " 'across': 140,\n",
              " 'allowing': 141,\n",
              " 'parameter': 142,\n",
              " 'efficient': 143,\n",
              " 'computational': 144,\n",
              " 'resources': 145,\n",
              " 'overfitting': 146,\n",
              " 'my': 147,\n",
              " 'dataset': 148,\n",
              " 'datasets': 149,\n",
              " 'augmentation': 150,\n",
              " 'promote': 151,\n",
              " 'labeled': 152,\n",
              " 'scenarios': 153,\n",
              " 'improve': 154,\n",
              " 'be': 155,\n",
              " 'llama2': 156,\n",
              " 'falcon': 157,\n",
              " 'difference': 158,\n",
              " 'understanding': 159,\n",
              " 'does': 160,\n",
              " 'mechanism': 161,\n",
              " 'mechanisms': 162,\n",
              " 'different': 163,\n",
              " 'output': 164,\n",
              " 'weights': 165,\n",
              " 'importance': 166,\n",
              " 'computes': 167,\n",
              " 'relationships': 168,\n",
              " 'within': 169,\n",
              " 'capturing': 170,\n",
              " 'into': 171,\n",
              " 'meaning': 172,\n",
              " 'crucial': 173,\n",
              " 'concept': 174,\n",
              " 'one': 175,\n",
              " 'then': 176,\n",
              " 'such': 177,\n",
              " 'entire': 178,\n",
              " 'both': 179,\n",
              " 'require': 180,\n",
              " 'common': 181,\n",
              " 'evaluation': 182,\n",
              " 'averaged': 183,\n",
              " 'often': 184,\n",
              " 'all': 185,\n",
              " 'development': 186,\n",
              " 'classes': 187,\n",
              " 'has': 188,\n",
              " 'relies': 189,\n",
              " 'impact': 190,\n",
              " 'scores': 191,\n",
              " 'out': 192,\n",
              " 'oov': 193,\n",
              " 'previously': 194,\n",
              " 'an': 195,\n",
              " 'generative': 196,\n",
              " 'discriminative': 197,\n",
              " 'aim': 198,\n",
              " 'generation': 199,\n",
              " 'categories': 200,\n",
              " 'fairness': 201,\n",
              " 'addressing': 202,\n",
              " 'outputs': 203,\n",
              " 'diverse': 204,\n",
              " 'challenges': 205,\n",
              " 'building': 206,\n",
              " 'multilingual': 207,\n",
              " 'languages': 208,\n",
              " 'biases': 209,\n",
              " 'coherent': 210,\n",
              " 'deploying': 211,\n",
              " 'masked': 212,\n",
              " 'prediction': 213,\n",
              " 'dragnuwa': 214,\n",
              " 'q1': 215,\n",
              " 'why': 216,\n",
              " 'a1': 217,\n",
              " 'domains': 218,\n",
              " 'complements': 219,\n",
              " 'excel': 220,\n",
              " 'contexts': 221,\n",
              " 'them': 222,\n",
              " 'powerful': 223,\n",
              " 'effective': 224,\n",
              " 'real': 225,\n",
              " 'world': 226,\n",
              " 'q2': 227,\n",
              " 'a2': 228,\n",
              " 'multiple': 229,\n",
              " 'simultaneously': 230,\n",
              " 'enhancing': 231,\n",
              " 'introduces': 232,\n",
              " 'prompts': 233,\n",
              " 'instructions': 234,\n",
              " 'grained': 235,\n",
              " 'control': 236,\n",
              " 'over': 237,\n",
              " 'behavior': 238,\n",
              " 'q3': 239,\n",
              " 'benefit': 240,\n",
              " 'a3': 241,\n",
              " 'reduces': 242,\n",
              " 'required': 243,\n",
              " 'accessible': 244,\n",
              " 'environments': 245,\n",
              " 'maintaining': 246,\n",
              " 'comparable': 247,\n",
              " 'standard': 248,\n",
              " 'q4': 249,\n",
              " 'will': 250,\n",
              " 'cause': 251,\n",
              " 'a4': 252,\n",
              " 'lead': 253,\n",
              " 'small': 254,\n",
              " 'early': 255,\n",
              " 'stopping': 256,\n",
              " 'dropout': 257,\n",
              " 'risk': 258,\n",
              " 'q5': 259,\n",
              " 'i': 260,\n",
              " 'tune': 261,\n",
              " 'if': 262,\n",
              " 'a5': 263,\n",
              " 'leveraging': 264,\n",
              " 'similar': 265,\n",
              " 'adaptability': 266,\n",
              " 'useful': 267,\n",
              " 'q6': 268,\n",
              " 'a6': 269,\n",
              " 'meta': 270,\n",
              " 'facebook': 271,\n",
              " 'q7': 272,\n",
              " 'a7': 273,\n",
              " 'bus': 274,\n",
              " 'going': 275,\n",
              " 'fro': 276,\n",
              " 'sheohar': 277,\n",
              " 'muzaffarpur': 278,\n",
              " 'q8': 279,\n",
              " 'a8': 280,\n",
              " 'corpus': 281,\n",
              " 'general': 282,\n",
              " 'taking': 283,\n",
              " 'domain': 284,\n",
              " 'further': 285,\n",
              " 'provides': 286,\n",
              " 'broad': 287,\n",
              " 'tailors': 288,\n",
              " 'well': 289,\n",
              " 'q9': 290,\n",
              " 'work': 291,\n",
              " 'a9': 292,\n",
              " 'enable': 293,\n",
              " 'parts': 294,\n",
              " 'assigns': 295,\n",
              " 'indicating': 296,\n",
              " 'weighted': 297,\n",
              " 'sum': 298,\n",
              " 'improves': 299,\n",
              " 'q10': 300,\n",
              " 'role': 301,\n",
              " 'natural': 302,\n",
              " 'a10': 303,\n",
              " 'representations': 304,\n",
              " 'vector': 305,\n",
              " 'space': 306,\n",
              " 'word2vec': 307,\n",
              " 'glove': 308,\n",
              " 'map': 309,\n",
              " 'continuous': 310,\n",
              " 'valued': 311,\n",
              " 'vectors': 312,\n",
              " 'semantic': 313,\n",
              " 'convert': 314,\n",
              " 'discrete': 315,\n",
              " 'format': 316,\n",
              " 'neural': 317,\n",
              " 'networks': 318,\n",
              " 'q11': 319,\n",
              " 'explain': 320,\n",
              " 'a11': 321,\n",
              " 'gained': 322,\n",
              " 'another': 323,\n",
              " 'excellent': 324,\n",
              " 'first': 325,\n",
              " 'massive': 326,\n",
              " 'amount': 327,\n",
              " 'transferred': 328,\n",
              " 'downstream': 329,\n",
              " 'named': 330,\n",
              " 'entity': 331,\n",
              " 'recognition': 332,\n",
              " 'q12': 333,\n",
              " 'a12': 334,\n",
              " 'considering': 335,\n",
              " 'bidirectional': 336,\n",
              " 'means': 337,\n",
              " 'look': 338,\n",
              " 'left': 339,\n",
              " 'right': 340,\n",
              " \"word's\": 341,\n",
              " 'change': 342,\n",
              " 'depending': 343,\n",
              " 'surrounding': 344,\n",
              " 'proficient': 345,\n",
              " 'completion': 346,\n",
              " 'q13': 347,\n",
              " 'a13': 348,\n",
              " 'accuracy': 349,\n",
              " 'precision': 350,\n",
              " 'recall': 351,\n",
              " 'roc': 352,\n",
              " 'auc': 353,\n",
              " 'binary': 354,\n",
              " 'multi': 355,\n",
              " 'class': 356,\n",
              " 'micro': 357,\n",
              " 'macro': 358,\n",
              " 'confusion': 359,\n",
              " 'matrices': 360,\n",
              " 'additionally': 361,\n",
              " 'might': 362,\n",
              " 'specialized': 363,\n",
              " 'bleu': 364,\n",
              " 'rouge': 365,\n",
              " 'machine': 366,\n",
              " 'translation': 367,\n",
              " 'summarization': 368,\n",
              " 'q14': 369,\n",
              " 'significance': 370,\n",
              " 'modern': 371,\n",
              " 'a14': 372,\n",
              " 'introduced': 373,\n",
              " 'need': 374,\n",
              " 'paper': 375,\n",
              " 'revolutionized': 376,\n",
              " 'introducing': 377,\n",
              " 'highly': 378,\n",
              " 'parallelizable': 379,\n",
              " 'leverages': 380,\n",
              " 'transformers': 381,\n",
              " 'enabled': 382,\n",
              " 'many': 383,\n",
              " 'others': 384,\n",
              " 'set': 385,\n",
              " 'benchmarks': 386,\n",
              " 'due': 387,\n",
              " 'effectively': 388,\n",
              " 'q15': 389,\n",
              " 'differ': 390,\n",
              " 'a15': 391,\n",
              " 'predictions': 392,\n",
              " 'never': 393,\n",
              " 'seen': 394,\n",
              " 'number': 395,\n",
              " 'shots': 396,\n",
              " 'adaptation': 397,\n",
              " 'q16': 398,\n",
              " 'a16': 399,\n",
              " 'significant': 400,\n",
              " 'larger': 401,\n",
              " 'parameters': 402,\n",
              " 'complex': 403,\n",
              " 'better': 404,\n",
              " 'however': 405,\n",
              " 'memory': 406,\n",
              " 'trade': 407,\n",
              " 'off': 408,\n",
              " 'constraints': 409,\n",
              " 'q17': 410,\n",
              " 'describe': 411,\n",
              " 'a17': 412,\n",
              " 'weigh': 413,\n",
              " 'determine': 414,\n",
              " 'much': 415,\n",
              " 'should': 416,\n",
              " 'place': 417,\n",
              " 'efficiently': 418,\n",
              " 'component': 419,\n",
              " 'q18': 420,\n",
              " 'a18': 421,\n",
              " 'typically': 422,\n",
              " 'breaking': 423,\n",
              " 'down': 424,\n",
              " 'byte': 425,\n",
              " 'pair': 426,\n",
              " 'encoding': 427,\n",
              " 'bpe': 428,\n",
              " 'wordpiece': 429,\n",
              " 'represent': 430,\n",
              " 'unseen': 431,\n",
              " 'combinations': 432,\n",
              " 'known': 433,\n",
              " 'less': 434,\n",
              " 'issue': 435,\n",
              " 'tokenization': 436,\n",
              " 'because': 437,\n",
              " 'vast': 438,\n",
              " 'q19': 439,\n",
              " 'a19': 440,\n",
              " 'probability': 441,\n",
              " 'distribution': 442,\n",
              " 'including': 443,\n",
              " 'samples': 444,\n",
              " 'autoencoders': 445,\n",
              " 'boundary': 446,\n",
              " 'discriminate': 447,\n",
              " 'rather': 448,\n",
              " 'than': 449,\n",
              " 'q20': 450,\n",
              " 'addressed': 451,\n",
              " 'ensure': 452,\n",
              " 'a20': 453,\n",
              " 'careful': 454,\n",
              " 'curation': 455,\n",
              " 'design': 456,\n",
              " 'debiasing': 457,\n",
              " 're': 458,\n",
              " 'weighting': 459,\n",
              " 'auditing': 460,\n",
              " 'moreover': 461,\n",
              " 'involving': 462,\n",
              " 'teams': 463,\n",
              " 'reduce': 464,\n",
              " 'q21': 465,\n",
              " 'key': 466,\n",
              " 'a21': 467,\n",
              " 'poses': 468,\n",
              " 'handling': 469,\n",
              " 'structures': 470,\n",
              " 'availability': 471,\n",
              " 'managing': 472,\n",
              " 'complexity': 473,\n",
              " 'effectiveness': 474,\n",
              " 'mitigating': 475,\n",
              " 'important': 476,\n",
              " 'q22': 477,\n",
              " 'contextually': 478,\n",
              " 'relevant': 479,\n",
              " 'a22': 480,\n",
              " 'employ': 481,\n",
              " 'autoregressive': 482,\n",
              " 'decoding': 483,\n",
              " 'where': 484,\n",
              " 'time': 485,\n",
              " 'generated': 486,\n",
              " 'continues': 487,\n",
              " 'until': 488,\n",
              " 'desired': 489,\n",
              " 'length': 490,\n",
              " 'reached': 491,\n",
              " 'coherence': 492,\n",
              " 'relevance': 493,\n",
              " 'prompt': 494,\n",
              " 'q23': 495,\n",
              " 'a23': 496,\n",
              " 'transparency': 497,\n",
              " 'interpretability': 498,\n",
              " 'guarding': 499,\n",
              " 'against': 500,\n",
              " 'malicious': 501,\n",
              " 'respecting': 502,\n",
              " 'privacy': 503,\n",
              " 'concerns': 504,\n",
              " 'unintended': 505,\n",
              " 'consequences': 506,\n",
              " 'responsible': 507,\n",
              " 'deployment': 508,\n",
              " 'risks': 509,\n",
              " 'q24': 510,\n",
              " 'a24': 511,\n",
              " 'randomly': 512,\n",
              " 'masking': 513,\n",
              " 'predicting': 514,\n",
              " 'q25': 515,\n",
              " 'a25': 516,\n",
              " 'achieve': 517,\n",
              " 'controllable': 518,\n",
              " 'video': 519}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for sentence in data.split('\\n'):\n",
        "  tokenized_sentence=token.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    l.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "xZX-iVThIKD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(l)"
      ],
      "metadata": {
        "id": "ulOZQeziLQM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max([len(x) for x in l])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvsdVqqqLHXB",
        "outputId": "d0f67d39-25d3-46b0-ef06-c2cdaaef9625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences=pad_sequences(l,maxlen=76,padding='pre')"
      ],
      "metadata": {
        "id": "o8jb2nUELSS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "VMYmC9fiMC02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "j59-DDS9MS_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMnnJWaTO32f",
        "outputId": "b8b33232-cfad-4fa0-ffb5-a9527334c009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1456, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAsuc_rZO6TM",
        "outputId": "d072bbd1-c5e5-40a6-af6c-49b747a80cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1456,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=520)"
      ],
      "metadata": {
        "id": "FUeI1yAWO-d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgI4hkL6O_Ow",
        "outputId": "b1301a8d-66e8-4afa-afb2-1bd6853ef4e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1456, 520)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "rnEO_uhHPQbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(520, 100, input_length=56))\n",
        "model.add(LSTM(150))\n",
        "\n",
        "model.add(Dense(520, activation='softmax'))"
      ],
      "metadata": {
        "id": "WyXT6XhePV1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2HN1yLszPiUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2VZDZuxPkST",
        "outputId": "d259ce8f-e0e9-4a36-dc34-cf47b99b294d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 56, 100)           52000     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 520)               78520     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 281120 (1.07 MB)\n",
            "Trainable params: 281120 (1.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "id": "BrMep01_PrZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}